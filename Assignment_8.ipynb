{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhiramsaigoud/2203A51272-B18/blob/main/Assignment_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example text data (you can replace this with any larger corpus) text = \"\"\" Once upon a time, there was a little girl named Red Riding Hood. She loved to visit her grandmother, who lived in the woods. One day, her mother asked her to take a basket of goodies to her grandmother. On her way through the woods, she met a big bad wolf who wanted to eat her. [CO5]\n",
        "(i) Build the Transformer Model on above dataset"
      ],
      "metadata": {
        "id": "hzRyR2Xhcay9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq917oipcXZo",
        "outputId": "e5684ee6-4009-4657-9f74-a9b369637dd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized input ids: tensor([[ 7454,  2402,   257,   640,    11,   612,   373,   257,  1310,  2576,\n",
            "          3706,  2297, 36032, 17233,    13,  1375,  6151,   284,  3187,   607,\n",
            "         18410,    11,   508,  5615,   287,   262, 16479,    13,  1881,  1110,\n",
            "            11,   607,  2802,  1965,   607,   284,  1011,   257,  7988,   286,\n",
            "         39863,   284,   607, 18410,    13,  1550,   607,   835,   832,   262,\n",
            "         16479,    11,   673,  1138,   257,  1263,  2089, 17481,   508,  2227,\n",
            "           284,  4483,   607,    13]])\n",
            "Loss: 2.5232996940612793\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "text = \"\"\"Once upon a time, there was a little girl named Red Riding Hood. She loved to visit her grandmother, who lived in the woods. One day, her mother asked her to take a basket of goodies to her grandmother. On her way through the woods, she met a big bad wolf who wanted to eat her.\"\"\"\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "\n",
        "input_ids = tokens['input_ids']\n",
        "\n",
        "print(f\"Tokenized input ids: {input_ids}\")\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "output = model(input_ids.to(device), labels=input_ids.to(device))\n",
        "loss = output.loss\n",
        "logits = output.logits\n",
        "\n",
        "print(f\"Loss: {loss.item()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(ii) Train the model using 20, 60, 70 epochs"
      ],
      "metadata": {
        "id": "U8SNrfvsd5lZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, TrainingArguments, Trainer\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "def train_model(num_epochs):\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./results_{num_epochs}_epochs\",\n",
        "        num_train_epochs=num_epochs,\n",
        "        per_device_train_batch_size=1,\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=10,\n",
        "        save_steps=10,\n",
        "        save_total_limit=2,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=dataset,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    print(f\"Training completed for {num_epochs} epochs.\")\n",
        "\n",
        "train_model(20)\n",
        "train_model(60)\n",
        "train_model(70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "Bcaj16rnejId",
        "outputId": "65344528-beb1-4116-f6de-0a365f756c89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 01:05, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.405100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.199500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed for 20 epochs.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 03:00, Epoch 60/60]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.129300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.022800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.019800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.028700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.020100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.056400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed for 60 epochs.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [70/70 04:03, Epoch 70/70]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.066000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.014200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.012900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.010400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.029600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.009200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed for 70 epochs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " (iii) After training, use the model to generate new text by feeding it an initial seed text\n",
        "\n"
      ],
      "metadata": {
        "id": "JgbPwWdpg35-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import warnings\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"Setting `pad_token_id` to `eos_token_id`\")\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model.config.pad_token_id = tokenizer.eos_token_id\n",
        "model.eval()\n",
        "\n",
        "seed_text = \"Once upon a time\"\n",
        "\n",
        "input_ids = tokenizer.encode(seed_text, return_tensors=\"pt\")\n",
        "attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    attention_mask=attention_mask,\n",
        "    max_length=50,\n",
        "    num_return_sequences=1,\n",
        "    no_repeat_ngram_size=2,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1yHqKjEg4UA",
        "outputId": "8a6c4d69-adbd-4b34-ff2c-d8cc19d80aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time, the world was a place of great beauty and great danger. The world of the gods was the place where the great gods were born, and where they were to live.\n",
            "\n",
            "The world that was created was not the same\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(iv) Experimenting and Improving the Model by large dataset and hyper tune parameter.\n",
        "\n"
      ],
      "metadata": {
        "id": "47Kr2JzhhcLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "text = \"\"\"Once upon a time, there was a little girl named Red Riding Hood. She loved to visit her grandmother, who lived in the woods. One day, her mother asked her to take a basket of goodies to her grandmother. On her way through the woods, she met a big bad wolf who wanted to eat her.\"\"\"\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "\n",
        "input_ids = tokens['input_ids']\n",
        "attention_mask = tokens.get('attention_mask', torch.ones_like(input_ids))\n",
        "\n",
        "print(f\"Tokenized input ids: {input_ids}\")\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "output = model(input_ids.to(device), attention_mask=attention_mask.to(device), labels=input_ids.to(device))\n",
        "loss = output.loss\n",
        "logits = output.logits\n",
        "\n",
        "print(f\"Loss: {loss.item()}\")\n",
        "\n",
        "model.eval()\n",
        "generated_text = model.generate(\n",
        "    input_ids.to(device),\n",
        "    attention_mask=attention_mask.to(device),\n",
        "    max_length=100,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.92,\n",
        "    temperature=0.7,\n",
        "    num_return_sequences=1,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "generated_text = tokenizer.decode(generated_text[0], skip_special_tokens=True)\n",
        "print(f\"Generated Text: {generated_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voZYm8cIhcl_",
        "outputId": "0aa52126-eb27-4182-dd8c-a30a68af3c3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized input ids: tensor([[ 7454,  2402,   257,   640,    11,   612,   373,   257,  1310,  2576,\n",
            "          3706,  2297, 36032, 17233,    13,  1375,  6151,   284,  3187,   607,\n",
            "         18410,    11,   508,  5615,   287,   262, 16479,    13,  1881,  1110,\n",
            "            11,   607,  2802,  1965,   607,   284,  1011,   257,  7988,   286,\n",
            "         39863,   284,   607, 18410,    13,  1550,   607,   835,   832,   262,\n",
            "         16479,    11,   673,  1138,   257,  1263,  2089, 17481,   508,  2227,\n",
            "           284,  4483,   607,    13]])\n",
            "Loss: 2.5232996940612793\n",
            "Generated Text: Once upon a time, there was a little girl named Red Riding Hood. She loved to visit her grandmother, who lived in the woods. One day, her mother asked her to take a basket of goodies to her grandmother. On her way through the woods, she met a big bad wolf who wanted to eat her. When she told her mother that she had been eaten, the wolf attacked her.\n",
            "\n",
            "So, she went to the forest and discovered that the wolf was a big bad wolf,\n"
          ]
        }
      ]
    }
  ]
}